From 187b9e52a6d715db9d66d4a770a90a9c96505818 Mon Sep 17 00:00:00 2001
From: Justin <earthbound.iap@gmail.com>
Date: Sun, 5 Feb 2012 15:47:32 -0500
Subject: [PATCH 25/35] ASHMEM: Add cache flush routines
 <-(zachariasmaladroit)


diff --git a/Kernel/include/linux/ashmem.h b/Kernel/include/linux/ashmem.h
index 1976b10..a67dbf7 100644
--- a/Kernel/include/linux/ashmem.h
+++ b/Kernel/include/linux/ashmem.h
@@ -44,5 +44,6 @@ struct ashmem_pin {
 #define ASHMEM_UNPIN		_IOW(__ASHMEMIOC, 8, struct ashmem_pin)
 #define ASHMEM_GET_PIN_STATUS	_IO(__ASHMEMIOC, 9)
 #define ASHMEM_PURGE_ALL_CACHES	_IO(__ASHMEMIOC, 10)
+#define ASHMEM_CACHE_FLUSH_RANGE  _IO(__ASHMEMIOC, 11)
 
 #endif	/* _LINUX_ASHMEM_H */
diff --git a/Kernel/mm/ashmem.c b/Kernel/mm/ashmem.c
index 00beada..0083f28 100644
--- a/Kernel/mm/ashmem.c
+++ b/Kernel/mm/ashmem.c
@@ -29,6 +29,7 @@
 #include <linux/mutex.h>
 #include <linux/shmem_fs.h>
 #include <linux/ashmem.h>
+#include <asm/cacheflush.h>
 
 #define ASHMEM_NAME_PREFIX "dev/ashmem/"
 #define ASHMEM_NAME_PREFIX_LEN (sizeof(ASHMEM_NAME_PREFIX) - 1)
@@ -45,6 +46,8 @@ struct ashmem_area {
 	struct list_head unpinned_list;	/* list of all ashmem areas */
 	struct file *file;		/* the shmem-based backing file */
 	size_t size;			/* size of the mapping, in bytes */
+	unsigned long vm_start;    	/* Start address of vm_area
+          			    	 * which maps this ashmem */
 	unsigned long prot_mask;	/* allowed prot bits, as vm_flags */
 };
 
@@ -326,6 +329,7 @@ static int ashmem_mmap(struct file *file, struct vm_area_struct *vma)
 		vma->vm_file = asma->file;
 	}
 	vma->vm_flags |= VM_CAN_NONLINEAR;
+	asma->vm_start = vma->vm_start;
 
 out:
 	mutex_unlock(&ashmem_mutex);
@@ -627,6 +631,81 @@ static int ashmem_pin_unpin(struct ashmem_area *asma, unsigned long cmd,
 	return ret;
 }
 
+#ifdef CONFIG_OUTER_CACHE
+static unsigned int kgsl_virtaddr_to_physaddr(unsigned int virtaddr)
+{
+  unsigned int physaddr = 0;
+  pgd_t *pgd_ptr = NULL;
+  pmd_t *pmd_ptr = NULL;
+  pte_t *pte_ptr = NULL, pte;
+
+  pgd_ptr = pgd_offset(current->mm, virtaddr);
+  if (pgd_none(*pgd) || pgd_bad(*pgd)) {
+    pr_info
+        ("Invalid pgd entry found while trying to convert virtual "
+         "address to physical\n");
+    return 0;
+  }
+
+  pmd_ptr = pmd_offset(pgd_ptr, virtaddr);
+  if (pmd_none(*pmd_ptr) || pmd_bad(*pmd_ptr)) {
+    pr_info
+        ("Invalid pmd entry found while trying to convert virtual "
+         "address to physical\n");
+    return 0;
+  }
+
+  pte_ptr = pte_offset_map(pmd_ptr, virtaddr);
+  if (!pte_ptr) {
+    pr_info
+        ("Unable to map pte entry while trying to convert virtual "
+         "address to physical\n");
+    return 0;
+  }
+  pte = *pte_ptr;
+  physaddr = pte_pfn(pte);
+  pte_unmap(pte_ptr);
+  physaddr <<= PAGE_SHIFT;
+  return physaddr;
+}
+#endif
+
+static int ashmem_flush_cache_range(struct ashmem_area *asma)
+{
+#ifdef CONFIG_OUTER_CACHE
+  unsigned long end;
+#endif
+  unsigned long addr;
+  unsigned int size, result = 0;
+
+  mutex_lock(&ashmem_mutex);
+
+  size = asma->size;
+  addr = asma->vm_start;
+  if (!addr || (addr & (PAGE_SIZE - 1)) || !size ||
+    (size & (PAGE_SIZE - 1))) {
+    result =  -EINVAL;
+    goto done;
+  }
+
+  flush_cache_user_range(addr, addr + size);
+#ifdef CONFIG_OUTER_CACHE
+  for (end = addr; end < (addr + size); end += PAGE_SIZE) {
+    unsigned long physaddr;
+    physaddr = kgsl_virtaddr_to_physaddr(end);
+    if (!physaddr) {
+      result =  -EINVAL;
+      goto done;
+    }
+
+    outer_flush_range(physaddr, physaddr + PAGE_SIZE);
+  }
+#endif
+done:
+  mutex_unlock(&ashmem_mutex);
+  return 0;
+}
+
 static long ashmem_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 {
 	struct ashmem_area *asma = file->private_data;
@@ -667,6 +746,9 @@ static long ashmem_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 			ashmem_shrink(&ashmem_shrinker, ret, GFP_KERNEL);
 		}
 		break;
+	case ASHMEM_CACHE_FLUSH_RANGE:
+    `		ret = ashmem_flush_cache_range(asma);
+    		break;
 	}
 
 	return ret;
-- 
1.7.5.4

